{"metadata":{},"cells":[{"cell_type":"markdown","metadata":{},"source":["[![Code-Generator](https://badgen.net/badge/Template%20by/Code-Generator/ee4c2c?labelColor=eaa700)](https://github.com/pytorch-ignite/code-generator)\n\n# Image Classification Template by Code-Generator\n\nThis is the image classification template by Code-Generator using `resnet18` model and `cifar10` dataset from TorchVision and training is powered by PyTorch and PyTorch-Ignite.\n\n## Getting Started\n\nInstall the dependencies with `pip`:\n\n```sh\npip install -r requirements.txt --progress-bar off -U\n```\n\n## Training\n\n### 1 GPU Training\n\n```sh\npython main.py\n```\n"]},{"cell_type":"code","metadata":{},"source":["!pip install torch>=1.8.0 torchvision>=0.9.0 pytorch-ignite>=0.4.4 pyyaml  tensorboard "],"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{},"source":["### Create a config file\n"]},{"cell_type":"code","metadata":{},"source":["%%writefile config.yaml\n","seed: 666\ndata_path: ./\ntrain_batch_size: 32\neval_batch_size: 32\nnum_workers: 4\nmax_epochs: 20\ntrain_epoch_length: 1000\neval_epoch_length: 1000\nlr: 0.0001\nuse_amp: false\ndebug: false\nmodel: resnet18\nfilename_prefix: training\nn_saved: 2\nsave_every_iters: 1000\npatience: 3\noutput_dir: ./logs\nlog_every_iters: 2\n"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["from typing import Any\n\nimport ignite.distributed as idist\nimport torchvision\nimport torchvision.transforms as T\n\n\ndef setup_data(config: Any):\n    \"\"\"Download datasets and create dataloaders\n\n    Parameters\n    ----------\n    config: needs to contain `data_path`, `train_batch_size`, `eval_batch_size`, and `num_workers`\n    \"\"\"\n    local_rank = idist.get_local_rank()\n    transform = T.Compose(\n        [\n            T.ToTensor(),\n            T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n        ]\n    )\n\n    if local_rank > 0:\n        # Ensure that only rank 0 download the dataset\n        idist.barrier()\n\n    dataset_train = torchvision.datasets.CIFAR10(\n        root=config.data_path,\n        train=True,\n        download=True,\n        transform=transform,\n    )\n    dataset_eval = torchvision.datasets.CIFAR10(\n        root=config.data_path,\n        train=False,\n        download=True,\n        transform=transform,\n    )\n    if local_rank == 0:\n        # Ensure that only rank 0 download the dataset\n        idist.barrier()\n\n    dataloader_train = idist.auto_dataloader(\n        dataset_train,\n        batch_size=config.train_batch_size,\n        shuffle=True,\n        num_workers=config.num_workers,\n    )\n    dataloader_eval = idist.auto_dataloader(\n        dataset_eval,\n        batch_size=config.eval_batch_size,\n        shuffle=False,\n        num_workers=config.num_workers,\n    )\n    return dataloader_train, dataloader_eval\n"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["from torchvision import models\n\n\ndef setup_model(name):\n    if name in models.__dict__:\n        fn = models.__dict__[name]\n    else:\n        raise RuntimeError(f\"Unknown model name {name}\")\n\n    return fn(num_classes=10)\n"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["from typing import Any, Union\n\nimport ignite.distributed as idist\nimport torch\nfrom ignite.engine import DeterministicEngine, Engine, Events\nfrom torch.cuda.amp import autocast\nfrom torch.nn import Module\nfrom torch.optim import Optimizer\nfrom torch.utils.data import DistributedSampler, Sampler\n\n\ndef setup_trainer(\n    config: Any,\n    model: Module,\n    optimizer: Optimizer,\n    loss_fn: Module,\n    device: Union[str, torch.device],\n    train_sampler: Sampler,\n) -> Union[Engine, DeterministicEngine]:\n    def train_function(engine: Union[Engine, DeterministicEngine], batch: Any):\n        model.train()\n\n        samples = batch[0].to(device, non_blocking=True)\n        targets = batch[1].to(device, non_blocking=True)\n\n        with autocast(config.use_amp):\n            outputs = model(samples)\n            loss = loss_fn(outputs, targets)\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        train_loss = loss.item()\n        engine.state.metrics = {\n            \"epoch\": engine.state.epoch,\n            \"train_loss\": train_loss,\n        }\n        return {\"train_loss\": train_loss}\n\n\n    trainer = Engine(train_function)\n\n    # set epoch for distributed sampler\n    @trainer.on(Events.EPOCH_STARTED)\n    def set_epoch():\n        if idist.get_world_size() > 1 and isinstance(\n            train_sampler, DistributedSampler\n        ):\n            train_sampler.set_epoch(trainer.state.epoch - 1)\n\n    return trainer\n\n\ndef setup_evaluator(\n    config: Any,\n    model: Module,\n    device: Union[str, torch.device],\n) -> Engine:\n    @torch.no_grad()\n    def eval_function(engine: Engine, batch: Any):\n        model.eval()\n\n        samples = batch[0].to(device, non_blocking=True)\n        targets = batch[1].to(device, non_blocking=True)\n\n        with autocast(config.use_amp):\n            outputs = model(samples)\n\n        return outputs, targets\n\n    return Engine(eval_function)\n"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["import logging\nfrom argparse import ArgumentParser\nfrom datetime import datetime\nfrom logging import Logger\nfrom pathlib import Path\nfrom typing import Any, Mapping, Optional, Union\n\nimport ignite.distributed as idist\nimport torch\nimport yaml\nfrom ignite.contrib.engines import common\nfrom ignite.engine import Engine\nfrom ignite.engine.events import Events\nfrom ignite.handlers import Checkpoint, DiskSaver, global_step_from_engine\nfrom ignite.handlers.early_stopping import EarlyStopping\nfrom ignite.handlers.terminate_on_nan import TerminateOnNan\nfrom ignite.handlers.time_limit import TimeLimit\nfrom ignite.utils import setup_logger\n\n\ndef setup_parser():\n    with open(\"config.yaml\", \"r\") as f:\n        config = yaml.safe_load(f.read())\n\n    parser = ArgumentParser()\n    parser.add_argument(\"--backend\", default=None, type=str)\n    for k, v in config.items():\n        if isinstance(v, bool):\n            parser.add_argument(f\"--{k}\", action=\"store_true\")\n        else:\n            parser.add_argument(f\"--{k}\", default=v, type=type(v))\n\n    return parser\n\n\ndef log_metrics(engine: Engine, tag: str) -> None:\n    \"\"\"Log `engine.state.metrics` with given `engine` and `tag`.\n\n    Parameters\n    ----------\n    engine\n        instance of `Engine` which metrics to log.\n    tag\n        a string to add at the start of output.\n    \"\"\"\n    metrics_format = \"{0} [{1}/{2}]: {3}\".format(\n        tag, engine.state.epoch, engine.state.iteration, engine.state.metrics\n    )\n    engine.logger.info(metrics_format)\n\n\ndef resume_from(\n    to_load: Mapping,\n    checkpoint_fp: Union[str, Path],\n    logger: Logger,\n    strict: bool = True,\n    model_dir: Optional[str] = None,\n) -> None:\n    \"\"\"Loads state dict from a checkpoint file to resume the training.\n\n    Parameters\n    ----------\n    to_load\n        a dictionary with objects, e.g. {“model”: model, “optimizer”: optimizer, ...}\n    checkpoint_fp\n        path to the checkpoint file\n    logger\n        to log info about resuming from a checkpoint\n    strict\n        whether to strictly enforce that the keys in `state_dict` match the keys\n        returned by this module’s `state_dict()` function. Default: True\n    model_dir\n        directory in which to save the object\n    \"\"\"\n    if isinstance(checkpoint_fp, str) and checkpoint_fp.startswith(\"https://\"):\n        checkpoint = torch.hub.load_state_dict_from_url(\n            checkpoint_fp,\n            model_dir=model_dir,\n            map_location=\"cpu\",\n            check_hash=True,\n        )\n    else:\n        if isinstance(checkpoint_fp, str):\n            checkpoint_fp = Path(checkpoint_fp)\n\n        if not checkpoint_fp.exists():\n            raise FileNotFoundError(\n                f\"Given {str(checkpoint_fp)} does not exist.\"\n            )\n        checkpoint = torch.load(checkpoint_fp, map_location=\"cpu\")\n\n    Checkpoint.load_objects(\n        to_load=to_load, checkpoint=checkpoint, strict=strict\n    )\n    logger.info(\"Successfully resumed from a checkpoint: %s\", checkpoint_fp)\n\n\ndef setup_output_dir(config: Any, rank: int) -> Path:\n    \"\"\"Create output folder.\"\"\"\n    if rank == 0:\n        now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        name = f\"{now}-backend-{config.backend}-lr-{config.lr}\"\n        path = Path(config.output_dir, name)\n        path.mkdir(parents=True, exist_ok=True)\n        config.output_dir = path.as_posix()\n\n    return Path(idist.broadcast(config.output_dir, src=0))\n\n\ndef setup_logging(config: Any) -> Logger:\n    \"\"\"Setup logger with `ignite.utils.setup_logger()`.\n\n    Parameters\n    ----------\n    config\n        config object. config has to contain `verbose` and `output_dir` attribute.\n\n    Returns\n    -------\n    logger\n        an instance of `Logger`\n    \"\"\"\n    green = \"\\033[32m\"\n    reset = \"\\033[0m\"\n    logger = setup_logger(\n        name=f\"{green}[ignite]{reset}\",\n        level=logging.DEBUG if config.debug else logging.INFO,\n        format=\"%(name)s: %(message)s\",\n        filepath=config.output_dir / \"training-info.log\",\n    )\n    return logger\n\n\ndef setup_handlers(\n    trainer: Engine,\n    evaluator: Engine,\n    config: Any,\n    to_save_train: Optional[dict] = None,\n    to_save_eval: Optional[dict] = None,\n):\n    \"\"\"Setup Ignite handlers.\"\"\"\n\n    ckpt_handler_train = ckpt_handler_eval = None\n    # checkpointing\n    saver = DiskSaver(config.output_dir / \"checkpoints\", require_empty=False)\n    ckpt_handler_train = Checkpoint(\n        to_save_train,\n        saver,\n        filename_prefix=config.filename_prefix,\n        n_saved=config.n_saved,\n    )\n    trainer.add_event_handler(\n        Events.ITERATION_COMPLETED(every=config.save_every_iters),\n        ckpt_handler_train,\n    )\n    global_step_transform = None\n    if to_save_train.get(\"trainer\", None) is not None:\n        global_step_transform = global_step_from_engine(\n            to_save_train[\"trainer\"]\n        )\n    ckpt_handler_eval = Checkpoint(\n        to_save_eval,\n        saver,\n        filename_prefix=\"best\",\n        n_saved=config.n_saved,\n        global_step_transform=global_step_transform,\n        score_name=\"eval_accuracy\",\n        score_function=Checkpoint.get_default_score_fn(\"eval_accuracy\"),\n    )\n    evaluator.add_event_handler(\n        Events.EPOCH_COMPLETED(every=1), ckpt_handler_eval\n    )\n    # early stopping\n    def score_fn(engine: Engine):\n        return -engine.state.metrics[\"eval_loss\"]\n\n    es = EarlyStopping(config.patience, score_fn, trainer)\n    evaluator.add_event_handler(Events.EPOCH_COMPLETED, es)\n    return ckpt_handler_train, ckpt_handler_eval\n\n\ndef setup_exp_logging(config, trainer, optimizers, evaluators):\n    \"\"\"Setup Experiment Tracking logger from Ignite.\"\"\"\n    logger = common.setup_tb_logging(\n        config.output_dir,\n        trainer,\n        optimizers,\n        evaluators,\n        config.log_every_iters,\n    )\n    return logger\n"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["from pprint import pformat\nfrom typing import Any\n\nimport ignite.distributed as idist\nimport yaml\nfrom data import setup_data\nfrom ignite.engine import Events\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.utils import manual_seed\nfrom models import setup_model\nfrom torch import nn, optim\nfrom trainers import setup_evaluator, setup_trainer\nfrom utils import *\n\n\ndef run(local_rank: int, config: Any):\n\n    # make a certain seed\n    rank = idist.get_rank()\n    manual_seed(config.seed + rank)\n\n    # create output folder\n    config.output_dir = setup_output_dir(config, rank)\n\n    # donwload datasets and create dataloaders\n    dataloader_train, dataloader_eval = setup_data(config)\n\n    # model, optimizer, loss function, device\n    device = idist.device()\n    model = idist.auto_model(setup_model(config.model))\n    optimizer = idist.auto_optim(optim.Adam(model.parameters(), lr=config.lr))\n    loss_fn = nn.CrossEntropyLoss().to(device=device)\n\n    # trainer and evaluator\n    trainer = setup_trainer(\n        config, model, optimizer, loss_fn, device, dataloader_train.sampler\n    )\n    evaluator = setup_evaluator(config, model, device)\n\n    # attach metrics to evaluator\n    accuracy = Accuracy(device=device)\n    metrics = {\n        \"eval_accuracy\": accuracy,\n        \"eval_loss\": Loss(loss_fn, device=device),\n        \"eval_error\": (1.0 - accuracy) * 100,\n    }\n    for name, metric in metrics.items():\n        metric.attach(evaluator, name)\n\n    # setup engines logger with python logging\n    # print training configurations\n    logger = setup_logging(config)\n    logger.info(\"Configuration: \\n%s\", pformat(vars(config)))\n    (config.output_dir / \"config-lock.yaml\").write_text(yaml.dump(config))\n    trainer.logger = evaluator.logger = logger\n\n    # setup ignite handlers\n    to_save_train = {\"model\": model, \"optimizer\": optimizer, \"trainer\": trainer}\n    to_save_eval = {\"model\": model}\n    ckpt_handler_train, ckpt_handler_eval = setup_handlers(\n        trainer, evaluator, config, to_save_train, to_save_eval\n    )\n    # experiment tracking\n    if rank == 0:\n        exp_logger = setup_exp_logging(config, trainer, optimizer, evaluator)\n\n    # print metrics to the stderr\n    # with `add_event_handler` API\n    # for training stats\n    trainer.add_event_handler(\n        Events.ITERATION_COMPLETED(every=config.log_every_iters),\n        log_metrics,\n        tag=\"train\",\n    )\n\n    # run evaluation at every training epoch end\n    # with shortcut `on` decorator API and\n    # print metrics to the stderr\n    # again with `add_event_handler` API\n    # for evaluation stats\n    @trainer.on(Events.EPOCH_COMPLETED(every=1))\n    def _():\n        evaluator.run(dataloader_eval, epoch_length=config.eval_epoch_length)\n        log_metrics(evaluator, \"eval\")\n\n    # let's try run evaluation first as a sanity check\n    @trainer.on(Events.STARTED)\n    def _():\n        evaluator.run(dataloader_eval, epoch_length=config.eval_epoch_length)\n\n    # setup if done. let's run the training\n    trainer.run(\n        dataloader_train,\n        max_epochs=config.max_epochs,\n        epoch_length=config.train_epoch_length,\n    )\n    # close logger\n    if rank == 0:\n        exp_logger.close()\n\n    # show last checkpoint names\n    logger.info(\n        \"Last training checkpoint name - %s\",\n        ckpt_handler_train.last_checkpoint,\n    )\n\n    logger.info(\n        \"Last evaluation checkpoint name - %s\",\n        ckpt_handler_eval.last_checkpoint,\n    )\n\n\n# main entrypoint\ndef main():\n    config = setup_parser().parse_args()\n    with idist.Parallel(config.backend) as p:\n        p.run(run, config=config)\n\n\nif __name__ == \"__main__\":\n    main()\n"],"outputs":[],"execution_count":null}],"nbformat":4,"nbformat_minor":2}